{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "yqbyjI_-bi_e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "metadata": {
        "id": "Mo0ITcOmbi_g",
        "colab_type": "code",
        "outputId": "0858155e-d726-41b9-bc9c-dc1579256856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "BQWxErq1bi_n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MiniProject #3: Deep Reinforcement Learning"
      ]
    },
    {
      "metadata": {
        "id": "oYCiR2Txbi_o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "metadata": {
        "id": "d-4ktfrPbi_q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Context"
      ]
    },
    {
      "metadata": {
        "id": "jMigj0S3bi_r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "metadata": {
        "id": "wJylUHgcbi_t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "metadata": {
        "id": "3ODNk55tbi_u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The environment"
      ]
    },
    {
      "metadata": {
        "id": "fJtzUokEbi_w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "metadata": {
        "id": "_XHeETeUbi_x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "co5zbLcpbi_1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "metadata": {
        "id": "IHF_OZewbi_3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The Agent"
      ]
    },
    {
      "metadata": {
        "id": "N9oHkWqTbi_4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "metadata": {
        "id": "Oitdmuhqbi_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "            \n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q27wN5awbi_8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "metadata": {
        "id": "7FdRYpWZbi_9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*The function act chooses the next action to do. It returns a random action with probability ```epsilon``` and it returns the action with respect to the policy with probability ```1-epsilon ```. ```epsilon``` is essential because it controls the eploration-exploitation dilemma : if ```epsilon``` is too small, the agent will do little exploration and thus, will unlikely determine the optimal policy. If ```epsilon``` is too high, the agent will rarely follow the policy.*"
      ]
    },
    {
      "metadata": {
        "id": "1U5ggNN9bi__",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "metadata": {
        "id": "jHDey3WobjAA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "6IlU5W9wbjAA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "metadata": {
        "id": "bo3VNp77bjAD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "metadata": {
        "id": "eJA0G7HKbjAD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EFUiX8LBbjAH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "metadata": {
        "id": "ehvL3H5ybjAJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=11 # set small when debugging\n",
        "epochs_test=5 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AcqaMUv8bjAP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "metadata": {
        "id": "xVmXHPdybjAQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*```position``` contains the postion of the rat in the current state. The cell where it is located contains a 1, those that contain -1 are those where it cannot go. We can note that 2 lines and columns of -1 were added at the begining and the ending of the position and board grid to ensure that the rat sees a range of 2 cells.*\n",
        "\n",
        "*```board``` contains the reward that the rat would get if it went on each cell.*"
      ]
    },
    {
      "metadata": {
        "id": "-RCqPgvRbjAQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Random Agent"
      ]
    },
    {
      "metadata": {
        "id": "HoGpTEa9bjAR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "metadata": {
        "id": "zG_MX9vVbjAS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        #pick a random action between 0 and 3\n",
        "        return np.random.randint(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4m41eukbjAX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "metadata": {
        "id": "KQ3JrXP7bjAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        #starting state\n",
        "        state = env.reset()\n",
        "\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # get random action\n",
        "            action = agent.act(state)\n",
        "            # perform action and look at the results\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "        \n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gzt7057KbjAc",
        "colab_type": "code",
        "outputId": "17a42821-d751-4a3a-fa1c-e2587d5e070b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 12.5/21.0. Average score (-8.5)\n",
            "Win/lose count 11.0/7.0. Average score (-2.25)\n",
            "Win/lose count 9.5/7.0. Average score (-0.6666666666666666)\n",
            "Win/lose count 12.5/15.0. Average score (-1.125)\n",
            "Win/lose count 11.0/12.0. Average score (-1.1)\n",
            "Final score: -1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "k3EkkCFibjAi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "metadata": {
        "id": "QkpyTzhlbjAi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8LC5pJpJbjAj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1)** We have that: \n",
        "$\\begin{array}\n",
        "QQ^{\\pi}(s,a) & = \\mathbb{E}_{p^\\pi}[\\sum_{t\\geq 0}\\gamma^t r(s_t, a_t)|s_0=s,a_0=a] \n",
        "\\end{array}$\n",
        "\n",
        "As we are in a Markov chain, we can write it as:\n",
        "\n",
        "$\\begin{array}\n",
        "QQ^{\\pi}(s,a) & = r(s,a) + \\sum_{a',s'}p(a',s'|s_0=s,a_0=a)\\mathbb{E}[\\sum_{t\\geq 1}\\gamma^t r(s_t, a_t)|s_1=s',a_1=a'] \n",
        "\\end{array}$\n",
        "\n",
        "We can factorize by $\\gamma$ and make the variable change $t'=t-1$ and we get:\n",
        "\n",
        "$\\begin{array}\n",
        "QQ^{\\pi}(s,a) & = r(s,a) + \\sum_{a',s'}p(a',s'|s_0=s,a_0=a)\\gamma Q^{\\pi}(s',a')\\\\\n",
        "& = \\mathbb{E}_{(s',a')\\sim p(.|s,a)}[r(s,a) + \\gamma Q^{\\pi}(s',a')]\n",
        "\\end{array}$"
      ]
    },
    {
      "metadata": {
        "id": "XCNOYEwfscdF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2)** We have:\n",
        "\n",
        "$\\begin{array}QQ^*(s,a) & =\\underset{\\pi}{\\max} Q^{\\pi}(s,a)\\\\\n",
        "& = r(s,a) + \\gamma \\underset{\\pi}{\\max} \\mathbb{E}_{(s',a')\\sim p(.|s,a)}[Q^{\\pi}(s',a')]\n",
        "\\end{array}$\n",
        "\n",
        "We also have:\n",
        "\n",
        "$\\begin{array}\n",
        "k\\max_{\\pi}\\mathbb{E}_{(s',a')\\sim p(.|s,a)}[Q^{\\pi}(s',a')] & \\leq \\mathbb{E}_{s'\\sim \\pi^*(.|s,a)}[\\underset{a'}{\\max}\\underset{\\pi}{\\max}Q^{\\pi}(s',a')]\\\\\n",
        " & \\leq \\mathbb{E}_{s'\\sim \\pi^*(.|s,a)}[\\underset{a'}{\\max}Q^{*}(s',a')]\n",
        "\\end{array}$\n",
        "\n",
        "And:\n",
        "\n",
        "$\\begin{array}\n",
        "k\\mathbb{E}_{s'\\sim \\pi^*(.|s,a)}[\\underset{a'}{\\max}Q^{*}(s',a')] & = \\underset{a'}{\\max} \\mathbb{E}_{s'\\sim \\pi^*(.|s,a)}[Q^{*}(s',a')] \\\\\n",
        "& \\leq \\underset{a'}{\\max} \\underset{s'}{\\max}\\mathbb{E}_{(s',a')\\sim p(.|s,a)}[Q^{\\pi^*}(s',a')] \\\\\n",
        "& \\leq \\underset{\\pi}{\\max} \\mathbb{E}_{(s',a')\\sim p(.|s,a)}[Q^{\\pi}(s',a')] \n",
        "\\end{array}$\n",
        "\n",
        "Thus, we have\n",
        "\n",
        "$ \\underset{\\pi}{\\max} \\mathbb{E}_{(s',a')\\sim p(.|s,a)}[Q^{\\pi}(s',a')]  = \\mathbb{E}_{s'\\sim \\pi^*(.|s,a)}[\\underset{a'}{\\max}Q^{*}(s',a')]$\n",
        "\n",
        "Hence, we get the equality:\n",
        "\n",
        "$$ Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].$$\n",
        "\n",
        "**3)** The optimal policy verifies the above equality, therefore we want to have the two parts the closest possible with our Q-function wich takes $\\theta$ as parameter. By minimizing the following loss, we can approach it :\n",
        "\n",
        "$\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}$"
      ]
    },
    {
      "metadata": {
        "id": "Sb9q44b3bjAk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "metadata": {
        "id": "NxFErwF0bjAl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        if (len(self.memory) <= self.max_memory):\n",
        "            self.memory.append(m)\n",
        "        else:\n",
        "            #remove the first element and add m at the end of the list\n",
        "            self.memory.pop(0)\n",
        "            self.memory.append(m)\n",
        "\n",
        "    def random_access(self):\n",
        "        n = len(self.memory)\n",
        "        index = np.random.randint(n)\n",
        "        return self.memory[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmE78E1mbjAp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "metadata": {
        "id": "3I1c86WebjAq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ye-HwgtybjAu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "metadata": {
        "id": "mIStcIcXbjAv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "\n",
        "    def learned_act(self, s):\n",
        "        # the prediction is the argmax of the ouput of the model\n",
        "        return np.argmax(self.model.predict(s.reshape(1,5,5,self.n_state)))\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            s, n_s, a, r, game_over = self.memory.random_access()\n",
        "            input_states[i] = s\n",
        "            #get the of the model and store them\n",
        "            target_q[i] = self.model.predict(s.reshape(1,5,5,self.n_state))\n",
        "            \n",
        "            if game_over:\n",
        "                target_q[i][a] = r\n",
        "                \n",
        "            else:\n",
        "                target_q[i][a] = r + self.discount * np.max(self.model.predict(n_s.reshape(1,5,5,self.n_state)))\n",
        "                \n",
        "                \n",
        "        ######## FILL IN\n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        \n",
        "        model = Sequential([\n",
        "            Flatten(),\n",
        "            Dense(64, input_shape=(5*5*self.n_state,), activation = 'relu'),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dense(4)]\n",
        "        )\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJ4Cyo4rbjAz",
        "colab_type": "code",
        "outputId": "4e4bce99-64ac-4e4e-b432-5fd5296a8529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        }
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.2, epsilon = 0.1, memory_size=2000, batch_size = 64)\n",
        "train(agent, env, 31, prefix='fc_train')\n",
        "HTML(display_videos('fc_train30.mp4'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 000/031 | Loss 0.0210 | Win/lose count 2.0/4.0 (-2.0)\n",
            "Epoch 001/031 | Loss 0.0088 | Win/lose count 1.0/1.0 (0.0)\n",
            "Epoch 002/031 | Loss 0.0436 | Win/lose count 5.5/6.0 (-0.5)\n",
            "Epoch 003/031 | Loss 0.0069 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 004/031 | Loss 0.0538 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 005/031 | Loss 0.0031 | Win/lose count 1.5/9.0 (-7.5)\n",
            "Epoch 006/031 | Loss 0.0071 | Win/lose count 5.0/6.0 (-1.0)\n",
            "Epoch 007/031 | Loss 0.0022 | Win/lose count 4.0/4.0 (0.0)\n",
            "Epoch 008/031 | Loss 0.0133 | Win/lose count 3.5/5.0 (-1.5)\n",
            "Epoch 009/031 | Loss 0.0028 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 010/031 | Loss 0.0089 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 011/031 | Loss 0.0040 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 012/031 | Loss 0.0042 | Win/lose count 2.5/5.0 (-2.5)\n",
            "Epoch 013/031 | Loss 0.0049 | Win/lose count 2.0/2.0 (0.0)\n",
            "Epoch 014/031 | Loss 0.0402 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 015/031 | Loss 0.0341 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 016/031 | Loss 0.0055 | Win/lose count 8.0/4.0 (4.0)\n",
            "Epoch 017/031 | Loss 0.0033 | Win/lose count 3.5/1.0 (2.5)\n",
            "Epoch 018/031 | Loss 0.0016 | Win/lose count 0.5/1.0 (-0.5)\n",
            "Epoch 019/031 | Loss 0.0029 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 020/031 | Loss 0.0038 | Win/lose count 2.5/0 (2.5)\n",
            "Epoch 021/031 | Loss 0.0017 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 022/031 | Loss 0.0278 | Win/lose count 1.5/5.0 (-3.5)\n",
            "Epoch 023/031 | Loss 0.0042 | Win/lose count 3.0/6.0 (-3.0)\n",
            "Epoch 024/031 | Loss 0.0055 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 025/031 | Loss 0.0048 | Win/lose count 13.0/8.0 (5.0)\n",
            "Epoch 026/031 | Loss 0.0032 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 027/031 | Loss 0.0286 | Win/lose count 2.0/0 (2.0)\n",
            "Epoch 028/031 | Loss 0.0060 | Win/lose count 3.5/1.0 (2.5)\n",
            "Epoch 029/031 | Loss 0.0020 | Win/lose count 10.0/3.0 (7.0)\n",
            "Epoch 030/031 | Loss 0.0024 | Win/lose count 9.0/5.0 (4.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "A2FGFafzbjA1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "metadata": {
        "id": "xLTJDMM8bjA3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential([\n",
        "                    Conv2D(40, (2,2), input_shape=(5,5,self.n_state), padding='same'),\n",
        "                    Activation('relu'),\n",
        "                    Conv2D(20, (2,2), padding='same'),\n",
        "                    Activation('relu'),\n",
        "                    Flatten(),\n",
        "                    Dense(4)]\n",
        "                )        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXVZmF86bjA6",
        "colab_type": "code",
        "outputId": "78f08cfd-70ab-405e-83cf-cbc8ec569bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        }
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.2, epsilon = 0.1, memory_size=2000, batch_size = 64)\n",
        "train(agent,env,31,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train30.mp4'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/031 | Loss 0.0033 | Win/lose count 4.5/6.0 (-1.5)\n",
            "Epoch 001/031 | Loss 0.0293 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 002/031 | Loss 0.0068 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 003/031 | Loss 0.0292 | Win/lose count 7.0/3.0 (4.0)\n",
            "Epoch 004/031 | Loss 0.0011 | Win/lose count 11.0/5.0 (6.0)\n",
            "Epoch 005/031 | Loss 0.0293 | Win/lose count 6.0/5.0 (1.0)\n",
            "Epoch 006/031 | Loss 0.0036 | Win/lose count 9.0/4.0 (5.0)\n",
            "Epoch 007/031 | Loss 0.0018 | Win/lose count 10.5/4.0 (6.5)\n",
            "Epoch 008/031 | Loss 0.0043 | Win/lose count 8.5/3.0 (5.5)\n",
            "Epoch 009/031 | Loss 0.0016 | Win/lose count 3.0/0 (3.0)\n",
            "Epoch 010/031 | Loss 0.0052 | Win/lose count 9.5/10.0 (-0.5)\n",
            "Epoch 011/031 | Loss 0.0024 | Win/lose count 11.0/5.0 (6.0)\n",
            "Epoch 012/031 | Loss 0.0323 | Win/lose count 12.5/2.0 (10.5)\n",
            "Epoch 013/031 | Loss 0.0277 | Win/lose count 7.0/1.0 (6.0)\n",
            "Epoch 014/031 | Loss 0.0274 | Win/lose count 14.0/3.0 (11.0)\n",
            "Epoch 015/031 | Loss 0.0038 | Win/lose count 10.5/4.0 (6.5)\n",
            "Epoch 016/031 | Loss 0.0266 | Win/lose count 12.5/1.0 (11.5)\n",
            "Epoch 017/031 | Loss 0.0256 | Win/lose count 20.5/2.0 (18.5)\n",
            "Epoch 018/031 | Loss 0.0021 | Win/lose count 13.5/3.0 (10.5)\n",
            "Epoch 019/031 | Loss 0.0020 | Win/lose count 8.0/1.0 (7.0)\n",
            "Epoch 020/031 | Loss 0.0030 | Win/lose count 8.5/2.0 (6.5)\n",
            "Epoch 021/031 | Loss 0.0045 | Win/lose count 9.0/3.0 (6.0)\n",
            "Epoch 022/031 | Loss 0.0242 | Win/lose count 18.5/1.0 (17.5)\n",
            "Epoch 023/031 | Loss 0.0017 | Win/lose count 16.5/3.0 (13.5)\n",
            "Epoch 024/031 | Loss 0.0016 | Win/lose count 16.5/4.0 (12.5)\n",
            "Epoch 025/031 | Loss 0.0487 | Win/lose count 18.0/5.0 (13.0)\n",
            "Epoch 026/031 | Loss 0.0027 | Win/lose count 8.5/0 (8.5)\n",
            "Epoch 027/031 | Loss 0.0026 | Win/lose count 7.0/2.0 (5.0)\n",
            "Epoch 028/031 | Loss 0.0015 | Win/lose count 10.0/2.0 (8.0)\n",
            "Epoch 029/031 | Loss 0.0328 | Win/lose count 17.0/8.0 (9.0)\n",
            "Epoch 030/031 | Loss 0.0021 | Win/lose count 13.5/3.0 (10.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "wDXuRaFNbjA8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "metadata": {
        "id": "ExwjEQucbjA8",
        "colab_type": "code",
        "outputId": "390e4061-fa07-493c-8672-62c57bdac0c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "epochs_test = 20\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 3.0/4.0. Average score (-1.0)\n",
            "Win/lose count 4.0/1.0. Average score (1.0)\n",
            "Win/lose count 5.5/2.0. Average score (1.8333333333333333)\n",
            "Win/lose count 16.0/4.0. Average score (4.375)\n",
            "Win/lose count 7.5/3.0. Average score (4.4)\n",
            "Win/lose count 17.5/5.0. Average score (5.75)\n",
            "Win/lose count 22.0/5.0. Average score (7.357142857142857)\n",
            "Win/lose count 20.0/1.0. Average score (8.8125)\n",
            "Win/lose count 10.0/2.0. Average score (8.722222222222221)\n",
            "Win/lose count 7.5/2.0. Average score (8.4)\n",
            "Win/lose count 13.5/4.0. Average score (8.5)\n",
            "Win/lose count 7.5/2.0. Average score (8.25)\n",
            "Win/lose count 4.0/3.0. Average score (7.6923076923076925)\n",
            "Win/lose count 3.0/3.0. Average score (7.142857142857143)\n",
            "Win/lose count 8.5/4.0. Average score (6.966666666666667)\n",
            "Win/lose count 11.5/5.0. Average score (6.9375)\n",
            "Win/lose count 11.5/4.0. Average score (6.970588235294118)\n",
            "Win/lose count 10.0/4.0. Average score (6.916666666666667)\n",
            "Win/lose count 9.5/4.0. Average score (6.842105263157895)\n",
            "Win/lose count 11.5/3.0. Average score (6.925)\n",
            "Final score: 6.925\n",
            "Test of the FC\n",
            "Win/lose count 3.5/0. Average score (3.5)\n",
            "Win/lose count 2.5/1.0. Average score (2.5)\n",
            "Win/lose count 3.5/1.0. Average score (2.5)\n",
            "Win/lose count 5.0/2.0. Average score (2.625)\n",
            "Win/lose count 1.0/0. Average score (2.3)\n",
            "Win/lose count 4.0/3.0. Average score (2.0833333333333335)\n",
            "Win/lose count 7.5/3.0. Average score (2.4285714285714284)\n",
            "Win/lose count 7.5/1.0. Average score (2.9375)\n",
            "Win/lose count 9.5/3.0. Average score (3.3333333333333335)\n",
            "Win/lose count 11.0/3.0. Average score (3.8)\n",
            "Win/lose count 11.0/2.0. Average score (4.2727272727272725)\n",
            "Win/lose count 9.5/1.0. Average score (4.625)\n",
            "Win/lose count 2.5/0. Average score (4.461538461538462)\n",
            "Win/lose count 5.5/4.0. Average score (4.25)\n",
            "Win/lose count 2.0/0. Average score (4.1)\n",
            "Win/lose count 7.5/0. Average score (4.3125)\n",
            "Win/lose count 12.0/5.0. Average score (4.470588235294118)\n",
            "Win/lose count 8.0/5.0. Average score (4.388888888888889)\n",
            "Win/lose count 6.5/1.0. Average score (4.447368421052632)\n",
            "Win/lose count 6.0/0. Average score (4.525)\n",
            "Final score: 4.525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tjVAOMbObjBB",
        "colab_type": "code",
        "outputId": "7353ab53-79ee-449f-af6c-052ce184cf07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('cnn_test0.mp4'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "yP2c0SIkbjBE",
        "colab_type": "code",
        "outputId": "0dbad2aa-7bc3-4dcc-95fd-9f89712fff9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('fc_test0.mp4'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "tvFoRzaHbjBI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Le modèle de réseau convolutionels semble mieux que le modèle fully-connected. On peut remarquer qu'en moyenne, le réseau convolutif a des meilleurs résultats que le réseau fully-connected et que pendant l'entrainement, les scores sont bien mieux pour le cnn.*\n",
        "\n",
        "*Le réseau convolutif semble prendre moins de risque que l'autre modèle. En effet, lorsque l'on met une faible température, c'est à dire lorsqu'il y a peur de cases avec des récompenses, on observe que le cnn prends peu de mauvaise récompense alors que l'autre en recoit plus. En revanche, avec une température égale à 1, lorsque la grille est recouverte uniquement de récompenses positives, on voit que le réseau fully-connected explore plus que le cnn, ce qui lui donne de meilleurs scores. *\n",
        "\n",
        "*Le problème principal de ces deux réseaux est qu'ils ont tendance à rester sur place et à très peu explorer. En effet, dans ces cas là il ont une récompense nulle mais comme il se peu que l'état présent n'affiche pas de récompense positive, l'algorithme ne se risque pas à explorer et fait des aller-retour entre deux case.*"
      ]
    },
    {
      "metadata": {
        "id": "r2s5qqL_bjBJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "c4DhdehNbjBL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_explore(agent,env,epoch, decay_factor = 0.9, prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        \n",
        "        agent.set_epsilon(agent.epsilon*decay_factor)\n",
        "        \n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size, grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action, train=False):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        \n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        \n",
        "        #prise en compte du malus de position\n",
        "        reward = 0\n",
        "        if train:\n",
        "            reward = -self.malus_position[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "        reward = reward + self.board[self.x, self.y]\n",
        "        \n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "        \n",
        "        #on ré-initialise malus position à zero partout, sauf la position actuelle à 0.1\n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.malus_position[self.x,self.y] = 0.1\n",
        "\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1F6Pr4-mbjBR",
        "colab_type": "code",
        "outputId": "0e762f3d-7a40-4331-c30f-375e72f13b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1038
        }
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.6, memory_size=2000, batch_size = 64,n_state=3)\n",
        "train_explore(agent, env, 51, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore50.mp4'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/051 | Loss 0.0199 | Win/lose count 9.0/29.10000000000008 (-20.10000000000008)\n",
            "Epoch 001/051 | Loss 0.0169 | Win/lose count 5.5/24.100000000000055 (-18.600000000000055)\n",
            "Epoch 002/051 | Loss 0.0069 | Win/lose count 10.5/17.399999999999984 (-6.899999999999984)\n",
            "Epoch 003/051 | Loss 0.0091 | Win/lose count 9.5/19.90000000000002 (-10.40000000000002)\n",
            "Epoch 004/051 | Loss 0.0085 | Win/lose count 9.0/22.700000000000014 (-13.700000000000014)\n",
            "Epoch 005/051 | Loss 0.0145 | Win/lose count 16.5/16.49999999999997 (2.842170943040401e-14)\n",
            "Epoch 006/051 | Loss 0.0036 | Win/lose count 13.0/23.700000000000003 (-10.700000000000003)\n",
            "Epoch 007/051 | Loss 0.0087 | Win/lose count 8.5/20.50000000000001 (-12.00000000000001)\n",
            "Epoch 008/051 | Loss 0.0276 | Win/lose count 15.5/19.299999999999994 (-3.7999999999999936)\n",
            "Epoch 009/051 | Loss 0.0468 | Win/lose count 21.5/19.29999999999999 (2.20000000000001)\n",
            "Epoch 010/051 | Loss 0.0047 | Win/lose count 18.0/18.2 (-0.1999999999999993)\n",
            "Epoch 011/051 | Loss 0.0056 | Win/lose count 14.0/17.799999999999994 (-3.7999999999999936)\n",
            "Epoch 012/051 | Loss 0.0251 | Win/lose count 20.0/16.49999999999997 (3.5000000000000284)\n",
            "Epoch 013/051 | Loss 0.0182 | Win/lose count 19.0/18.299999999999983 (0.700000000000017)\n",
            "Epoch 014/051 | Loss 0.0084 | Win/lose count 19.0/15.799999999999965 (3.200000000000035)\n",
            "Epoch 015/051 | Loss 0.0201 | Win/lose count 18.5/14.999999999999973 (3.5000000000000266)\n",
            "Epoch 016/051 | Loss 0.0085 | Win/lose count 21.5/13.69999999999997 (7.800000000000029)\n",
            "Epoch 017/051 | Loss 0.0077 | Win/lose count 16.0/18.399999999999988 (-2.399999999999988)\n",
            "Epoch 018/051 | Loss 0.0290 | Win/lose count 18.5/14.199999999999969 (4.300000000000031)\n",
            "Epoch 019/051 | Loss 0.0290 | Win/lose count 17.5/14.899999999999963 (2.600000000000037)\n",
            "Epoch 020/051 | Loss 0.0522 | Win/lose count 13.0/17.099999999999977 (-4.0999999999999766)\n",
            "Epoch 021/051 | Loss 0.0063 | Win/lose count 18.0/16.99999999999998 (1.0000000000000213)\n",
            "Epoch 022/051 | Loss 0.0079 | Win/lose count 20.0/13.899999999999974 (6.100000000000026)\n",
            "Epoch 023/051 | Loss 0.0091 | Win/lose count 24.5/15.299999999999969 (9.200000000000031)\n",
            "Epoch 024/051 | Loss 0.0093 | Win/lose count 18.5/12.599999999999977 (5.9000000000000234)\n",
            "Epoch 025/051 | Loss 0.0212 | Win/lose count 6.0/19.200000000000003 (-13.200000000000003)\n",
            "Epoch 026/051 | Loss 0.0137 | Win/lose count 24.5/12.89999999999998 (11.60000000000002)\n",
            "Epoch 027/051 | Loss 0.0104 | Win/lose count 20.5/13.099999999999973 (7.400000000000027)\n",
            "Epoch 028/051 | Loss 0.0215 | Win/lose count 19.0/13.199999999999976 (5.800000000000024)\n",
            "Epoch 029/051 | Loss 0.0089 | Win/lose count 14.0/12.199999999999973 (1.8000000000000274)\n",
            "Epoch 030/051 | Loss 0.0202 | Win/lose count 18.5/14.399999999999965 (4.100000000000035)\n",
            "Epoch 031/051 | Loss 0.0304 | Win/lose count 20.0/13.69999999999997 (6.300000000000029)\n",
            "Epoch 032/051 | Loss 0.0141 | Win/lose count 21.0/14.099999999999966 (6.900000000000034)\n",
            "Epoch 033/051 | Loss 0.0099 | Win/lose count 8.0/17.59999999999998 (-9.59999999999998)\n",
            "Epoch 034/051 | Loss 0.0121 | Win/lose count 13.0/17.199999999999978 (-4.199999999999978)\n",
            "Epoch 035/051 | Loss 0.0114 | Win/lose count 20.5/16.899999999999984 (3.6000000000000156)\n",
            "Epoch 036/051 | Loss 0.0115 | Win/lose count 12.5/16.499999999999964 (-3.9999999999999645)\n",
            "Epoch 037/051 | Loss 0.0069 | Win/lose count 10.5/17.49999999999998 (-6.999999999999979)\n",
            "Epoch 038/051 | Loss 0.0049 | Win/lose count 15.5/14.499999999999964 (1.0000000000000355)\n",
            "Epoch 039/051 | Loss 0.0077 | Win/lose count 22.5/14.499999999999968 (8.000000000000032)\n",
            "Epoch 040/051 | Loss 0.0136 | Win/lose count 20.5/14.299999999999969 (6.200000000000031)\n",
            "Epoch 041/051 | Loss 0.0117 | Win/lose count 13.5/15.79999999999996 (-2.29999999999996)\n",
            "Epoch 042/051 | Loss 0.0074 | Win/lose count 14.0/15.79999999999996 (-1.7999999999999599)\n",
            "Epoch 043/051 | Loss 0.0121 | Win/lose count 10.0/14.699999999999964 (-4.699999999999964)\n",
            "Epoch 044/051 | Loss 0.0128 | Win/lose count 26.5/12.49999999999998 (14.00000000000002)\n",
            "Epoch 045/051 | Loss 0.0079 | Win/lose count 11.5/16.399999999999963 (-4.899999999999963)\n",
            "Epoch 046/051 | Loss 0.0220 | Win/lose count 23.0/12.699999999999974 (10.300000000000026)\n",
            "Epoch 047/051 | Loss 0.0136 | Win/lose count 23.5/10.499999999999982 (13.000000000000018)\n",
            "Epoch 048/051 | Loss 0.0190 | Win/lose count 16.5/14.599999999999968 (1.9000000000000323)\n",
            "Epoch 049/051 | Loss 0.0108 | Win/lose count 15.5/14.899999999999972 (0.6000000000000281)\n",
            "Epoch 050/051 | Loss 0.0149 | Win/lose count 11.0/14.599999999999964 (-3.599999999999964)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "rC1ce5cAbjBW",
        "colab_type": "code",
        "outputId": "02515554-d228-4dd3-acde-8a51ca2a968a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "epochs_test = 21\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore20.mp4'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 17.5/0. Average score (17.5)\n",
            "Win/lose count 18.0/1.0. Average score (17.25)\n",
            "Win/lose count 17.5/4.0. Average score (16.0)\n",
            "Win/lose count 5.5/1.0. Average score (13.125)\n",
            "Win/lose count 23.5/3.0. Average score (14.6)\n",
            "Win/lose count 13.5/3.0. Average score (13.916666666666666)\n",
            "Win/lose count 13.0/1.0. Average score (13.642857142857142)\n",
            "Win/lose count 7.0/0. Average score (12.8125)\n",
            "Win/lose count 21.0/2.0. Average score (13.5)\n",
            "Win/lose count 16.0/1.0. Average score (13.65)\n",
            "Win/lose count 17.5/2.0. Average score (13.818181818181818)\n",
            "Win/lose count 13.0/1.0. Average score (13.666666666666666)\n",
            "Win/lose count 9.0/0. Average score (13.307692307692308)\n",
            "Win/lose count 10.5/1.0. Average score (13.035714285714286)\n",
            "Win/lose count 19.0/5.0. Average score (13.1)\n",
            "Win/lose count 12.5/1.0. Average score (13.0)\n",
            "Win/lose count 2.0/0. Average score (12.352941176470589)\n",
            "Win/lose count 7.0/0. Average score (12.055555555555555)\n",
            "Win/lose count 20.5/1.0. Average score (12.447368421052632)\n",
            "Win/lose count 14.5/0. Average score (12.55)\n",
            "Win/lose count 13.0/2.0. Average score (12.476190476190476)\n",
            "Final score: 12.476190476190476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAF7RtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAL9ZYiEADP//vaG+BTYUyP+T7/8I/+5H7cfWfrixkIJvrVeQ9GAMl8a/5lGYaXpyc8t7R+vTNAEZz8ZS8pY/so8NlHfJ0KOy+BS4CivgU0mRv43zlLMMajLAeUnarh5ryDNsNHOjfAqmaPykmkxnOX0MwTxhdyDoZY1wjZsU/yinNIGAQGL2rIhBNKyUxuroUSGXPowg9GhJinPRQRuuOHZiyZZF9Ff7PFgVQ8TErLfuFqeQcX1epx6oyfyRcmRtme2UGZmL8z1w9lmFk8LTVKguXO571QA9tsfyyBphbPdPTMi2+KJiHntHfmVQHAhT9Pn9gqzJgfvgvCt8K3gADTJQm+A9X1SEoZq6k6sGRT9E8igzNkcTVk8OGx46he7QL8B9AT/BFB+J1vxgUgcOxqm8PXA1/El/uZQMyWIE/fA/m3nkQcRdvuyqNmdRf1QP6zoilswkZ792MN4WFTqSttgNX0duEaDN0v+BiQep7mOBsDggW2ZPO4lwRVp2aKB5kksM49aUJACTvPmRM3bM80l08IbWfRa82J5o6fd0j3dRfUmdcEmlNqcYPyCs1s4gerlnDTGxmQvymSF/dQF6NTTar1hR5bcBCS6cyXiFsYBgVUpq3MlfMcR7JozpL6UqeCwLna4wpoqzPmvWB74Z1zf5EAALmATx5lV9JcDMksASv5xEwMQaol4kcXN9oy7GeDh5JFGlK5xMzrcTz1DYLzQzs/RT9QVDe+gABdxeO+QEBRUxgyi+oCXJOTvLobOGh1h6M9b8j3bqgnTqK/mGOwt+IOtxyZrWaMSPERyRKT21o8gdg4pz/wgCj4kClSxZz7xGCzjiMUiDusqcI3hpc6RywsA6LYXO81wQPeIAGIYSdUe7xggH7vQmCVsQIUzUVBO1TE/A5yKE5CIMpYPyAEIoPN+qklF3Aga1ecSI4mjwMhmRqfwpDfg9G/+F+OolvxNvQN/FuoMC2Xwnrj17ItfCWV4R7MKuF4LNuAnEfFA5arCwC2yUUYTIGFQACDhAAAAE0GaIWxDP/6eEAHn9ffyYI+sI3oAAAAXQZpCPCGTKYQz//6eEAFGr3GhdN91uW0AAAAYQZpjSeEPJlMCGf/+nhAB8CnHP0YDsz+zAAAAGEGahEnhDyZTAhn//p4QAwshjn6MB2Z+LwAAABhBmqVJ4Q8mUwIZ//6eEASw4Rz+HOb6yf8AAAAYQZrGSeEPJlMCGf/+nhAEt+IedboGSGUNAAAAGUGa50nhDyZTAhv//qeEAkHRP9St9nyEqYEAAAAdQZsJSeEPJlMFETwz//6eEAiniH94QluuI+maSMAAAAAQAZ8oakK/AX8jtzrQwvDdwAAAABhBmypJ4Q8mUwIZ//6eEAR34h51ugZIZVUAAAAZQZtLSeEPJlMCG//+p4QBHfjp9RxoSHBdwAAAABlBm2xJ4Q8mUwIb//6nhAC6e6n6jjQkOEfAAAAAGEGbj0nhDyZTAhn//p4QAdH193ac3cW3uwAAABJBn61FETwr/wBiCPRAKYByJcEAAAAQAZ/OakK/AF+duE3GfXpweQAAABpBm9BJqEFomUwIb//+p4QAdH32Y/w+rbbVgAAAABlBm/FJ4QpSZTAhv/6nhACweif6rfMfiEvAAAAAIEGaFUnhDomUwIZ//p4QFs4nfHpxfAptLdq++0aOrV5VAAAAFUGeM0URPC//AZWediijp2sZDSng7gAAABABnlJ0Qr8BWsyngdMpuVCAAAAAEAGeVGpCvwIeCxr3lwKAZ8EAAAAZQZpWSahBaJlMCGf//p4QFL4nZ1ugW3MN6AAAABhBmndJ4QpSZTAhv/6nhAUvjToK1mNnwxcAAAAdQZqZSeEOiZTBTRMM//6eEBEu1H2S9bWIuf3MvuEAAAAPAZ64akK/Aeu2FVeAH/IjAAAAGkGauknhDyZTAhv//qeEAPh7LKf6jjQkODUhAAAAGEGa20nhDyZTAhv//qeEAKditIIRP8ttKwAAABtBmv5J4Q8mUwIZ//6eEAKh8TvirvOMjH1RC2EAAAARQZ8cRRE8K/8AiuaN5pveoZkAAAAPAZ89akK/AIrK3SjSHiY2AAAAGkGbP0moQWiZTAhv//6nhABsfYP8JwW6EmpAAAAAHUGbQUnhClJlMFESw3/+p4QARb46farzaojIyBEFAAAAEAGfYGpCvwA4oQCdeAJ/rYAAAAAdQZtjSeEOiZTBRMM//p4QAHG9ffqhHVud1xH1R2cAAAAQAZ+CakK/ABfiO3OtDC9lwAAAABlBm4RJ4Q8mUwIb//6nhAASb46fUcaEh1tBAAAAIUGbpknhDyZTBRE8M//+nhAALr7wADL/ibfVud1xH1TTgQAAABABn8VqQr8ACayfOdaGF/XBAAAAGEGbx0nhDyZTAhn//p4QAB0fX38iRH1i0wAAABhBm+hJ4Q8mUwIZ//6eEAATUQ4/ngv5JmwAAAAYQZoJSeEPJlMCG//+p4QABRsVpBCJ/lyTAAAAIEGaK0nhDyZTBRE8N//+p4QAB+weHFjUtww2f5bJH5d5AAAAEAGeSmpCvwAGmdU8mB6+dYAAAAAXQZpMSeEPJlMCG//+p4QACCj5jlcNuDkAAAAeQZpwSeEPJlMCGf/+nhAANP6+7tOXxBeqJ4b/6xCbAAAAH0GejkURPC//AAfxNkH/VXMspijHMsA8HMsg3pAPqmEAAAAPAZ6tdEK/AAcWKTG9QRxLAAAAEAGer2pCvwALEo0TImlaDcAAAAAaQZqxSahBaJlMCG///qeEABRvRP9VvmPxUkAAAAAZQZrSSeEKUmUwIb/+p4QAHwOM/1W+Y/E1IQAAAB9BmvZJ4Q6JlMCGf/6eEAC/+vv6kaANC+g/c1x9b54gAAAAFkGfFEURPC//AB2z79M4ofTlQ1LvA0AAAAAQAZ8zdEK/ACj5aoHTtQ35gQAAABABnzVqQr8AKO25FXgCf+qAAAAAGUGbN0moQWiZTAhn//6eEABT69xoXTfdck0AAAAXQZtYSeEKUmUwIZ/+nhAAVivcYI67I6UAAAAYQZt5SeEOiZTAhv/+p4QAFqxWkEIn+W6TAAAAGEGbmknhDyZTAhv//qeEABawUFeXIc6TgQAAABlBm71J4Q8mUwIb//6nhAAO0Dwp1nT7ro6AAAAAD0Gf20URPCv/AAxBGgcEwQAAAA8Bn/xqQr8ADEJWxbDdBMEAAAASQZv/SahBaJlMFPDf/qeEAAEnAAAAEAGeHmpCvwAMQlbFkc60IugAAAASQZoBSeEKUmUwUsN//qeEAAEnAAAAEAGeIGpCvwAMQlbFkc60IugAAAASQZojSeEOiZTBRMN//qeEAAEnAAAAEAGeQmpCvwAMQlbFkc60IugAAAASQZpFSeEPJlMFPDf//qeEAAEnAAAAEAGeZGpCvwAMQlbFkc60IukAAAASQZpnSeEPJlMFPDf//qeEAAEnAAAAEAGehmpCvwAMQlbFkc60IukAAAASQZqJSeEPJlMFPDf//qeEAAEnAAAAEAGeqGpCvwAMQlbFkc60IugAAAASQZqrSeEPJlMFPDf//qeEAAEnAAAAEAGeympCvwAMQlbFkc60IugAAAASQZrNSeEPJlMFPDf//qeEAAEnAAAAEAGe7GpCvwAMQlbFkc60IukAAAASQZrvSeEPJlMFPDf//qeEAAEnAAAAEAGfDmpCvwAMQlbFkc60IukAAAASQZsRSeEPJlMFPDf//qeEAAEnAAAAEAGfMGpCvwAMQlbFkc60IugAAAASQZszSeEPJlMFPDf//qeEAAEnAAAAEAGfUmpCvwAMQlbFkc60IugAAAASQZtVSeEPJlMFPDf//qeEAAEnAAAAEAGfdGpCvwAMQlbFkc60IukAAAASQZt3SeEPJlMFPDf//qeEAAEnAAAAEAGflmpCvwAMQlbFkc60IukAAAASQZuZSeEPJlMFPDf//qeEAAEnAAAAEAGfuGpCvwAMQlbFkc60IugAAAASQZu7SeEPJlMFPDf//qeEAAEnAAAAEAGf2mpCvwAMQlbFkc60IugAAAASQZvdSeEPJlMFPDf//qeEAAEnAAAAEAGf/GpCvwAMQlbFkc60IukAAAASQZv/SeEPJlMFPDf//qeEAAEnAAAAEAGeHmpCvwAMQlbFkc60IugAAAASQZoBSeEPJlMFPDf//qeEAAEnAAAAEAGeIGpCvwAMQlbFkc60IugAAAASQZojSeEPJlMFPDf//qeEAAEnAAAAEAGeQmpCvwAMQlbFkc60IugAAAASQZpFSeEPJlMFPDf//qeEAAEnAAAAEAGeZGpCvwAMQlbFkc60IukAAAASQZpnSeEPJlMFPDf//qeEAAEnAAAAEAGehmpCvwAMQlbFkc60IukAAAASQZqJSeEPJlMFPDf//qeEAAEnAAAAEAGeqGpCvwAMQlbFkc60IugAAAASQZqrSeEPJlMFPDf//qeEAAEnAAAAEAGeympCvwAMQlbFkc60IugAAAASQZrNSeEPJlMFPDf//qeEAAEnAAAAEAGe7GpCvwAMQlbFkc60IukAAAASQZrvSeEPJlMFPDf//qeEAAEnAAAAEAGfDmpCvwAMQlbFkc60IukAAAASQZsRSeEPJlMFPDf//qeEAAEnAAAAEAGfMGpCvwAMQlbFkc60IugAAAASQZszSeEPJlMFPDf//qeEAAEnAAAAEAGfUmpCvwAMQlbFkc60IugAAAASQZtVSeEPJlMFPDf//qeEAAEnAAAAEAGfdGpCvwAMQlbFkc60IukAAAASQZt3SeEPJlMFPDf//qeEAAEnAAAAEAGflmpCvwAMQlbFkc60IukAAAASQZuZSeEPJlMFPDf//qeEAAEnAAAAEAGfuGpCvwAMQlbFkc60IugAAAASQZu7SeEPJlMFPDf//qeEAAEnAAAAEAGf2mpCvwAMQlbFkc60IugAAAASQZvdSeEPJlMFPDf//qeEAAEnAAAAEAGf/GpCvwAMQlbFkc60IukAAAASQZv/SeEPJlMFPDf//qeEAAEnAAAAEAGeHmpCvwAMQlbFkc60IugAAAASQZoBSeEPJlMFPDf//qeEAAEnAAAAEAGeIGpCvwAMQlbFkc60IugAAAASQZojSeEPJlMFPDf//qeEAAEnAAAAEAGeQmpCvwAMQlbFkc60IugAAAASQZpFSeEPJlMFPDf//qeEAAEnAAAAEAGeZGpCvwAMQlbFkc60IukAAAASQZpnSeEPJlMFPDf//qeEAAEnAAAAEAGehmpCvwAMQlbFkc60IukAAAASQZqJSeEPJlMFPDf//qeEAAEnAAAAEAGeqGpCvwAMQlbFkc60IugAAAASQZqrSeEPJlMFPDf//qeEAAEnAAAAEAGeympCvwAMQlbFkc60IugAAAASQZrNSeEPJlMFPDf//qeEAAEnAAAAEAGe7GpCvwAMQlbFkc60IukAAAASQZrvSeEPJlMFPDf//qeEAAEnAAAAEAGfDmpCvwAMQlbFkc60IukAAAASQZsRSeEPJlMFPDf//qeEAAEnAAAAEAGfMGpCvwAMQlbFkc60IugAAAASQZszSeEPJlMFPDf//qeEAAEnAAAAEAGfUmpCvwAMQlbFkc60IugAAAASQZtVSeEPJlMFPDf//qeEAAEnAAAAEAGfdGpCvwAMQlbFkc60IukAAAASQZt3SeEPJlMFPDf//qeEAAEnAAAAEAGflmpCvwAMQlbFkc60IukAAAASQZuZSeEPJlMFPDf//qeEAAEnAAAAEAGfuGpCvwAMQlbFkc60IugAAAASQZu7SeEPJlMFPDf//qeEAAEnAAAAEAGf2mpCvwAMQlbFkc60IugAAAASQZvdSeEPJlMFPDf//qeEAAEnAAAAEAGf/GpCvwAMQlbFkc60IukAAAASQZv/SeEPJlMFPDf//qeEAAEnAAAAEAGeHmpCvwAMQlbFkc60IugAAAASQZoBSeEPJlMFPDf//qeEAAEnAAAAEAGeIGpCvwAMQlbFkc60IugAAAASQZojSeEPJlMFPDf//qeEAAEnAAAAEAGeQmpCvwAMQlbFkc60IugAAAASQZpFSeEPJlMFPDf//qeEAAEnAAAAEAGeZGpCvwAMQlbFkc60IukAAAASQZpnSeEPJlMFPDf//qeEAAEnAAAAEAGehmpCvwAMQlbFkc60IukAAAASQZqJSeEPJlMFPDf//qeEAAEnAAAAEAGeqGpCvwAMQlbFkc60IugAAAASQZqrSeEPJlMFPDf//qeEAAEnAAAAEAGeympCvwAMQlbFkc60IugAAAASQZrNSeEPJlMFPDf//qeEAAEnAAAAEAGe7GpCvwAMQlbFkc60IukAAAASQZrvSeEPJlMFPDf//qeEAAEnAAAAEAGfDmpCvwAMQlbFkc60IukAAAASQZsRSeEPJlMFPDf//qeEAAEnAAAAEAGfMGpCvwAMQlbFkc60IugAAAASQZszSeEPJlMFPDf//qeEAAEnAAAAEAGfUmpCvwAMQlbFkc60IugAAAASQZtVSeEPJlMFPDf//qeEAAEnAAAAEAGfdGpCvwAMQlbFkc60IukAAAASQZt3SeEPJlMFPDf//qeEAAEnAAAAEAGflmpCvwAMQlbFkc60IukAAAASQZuZSeEPJlMFPDf//qeEAAEnAAAAEAGfuGpCvwAMQlbFkc60IugAAAASQZu7SeEPJlMFPDf//qeEAAEnAAAAEAGf2mpCvwAMQlbFkc60IugAAAASQZvdSeEPJlMFPDf//qeEAAEnAAAAEAGf/GpCvwAMQlbFkc60IukAAAASQZv/SeEPJlMFPDf//qeEAAEnAAAAEAGeHmpCvwAMQlbFkc60IugAAAASQZoBSeEPJlMFPDf//qeEAAEnAAAAEAGeIGpCvwAMQlbFkc60IugAAAASQZojSeEPJlMFPDf//qeEAAEnAAAAEAGeQmpCvwAMQlbFkc60IugAAAASQZpFSeEPJlMFPDP//p4QAAR9AAAAEAGeZGpCvwAMQlbFkc60IukAAAASQZpnSeEPJlMFPDP//p4QAAR9AAAAEAGehmpCvwAMQlbFkc60IukAAAAaQZqJS+EIQ8kRggoB/IB/YeAU8K/+OEAAEXAAAAAkAZ6oakK/Aq9j7UHE3arDSSblqoYHLLW7zSog23uCMfnANcF4AAAL4G1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAB+QAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAsKdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAB+QAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAEQAAABEAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAfkAAABAAAAQAAAAAKgm1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAMgAAAZQAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAACi1taW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAntc3RibAAAAJVzdHNkAAAAAAAAAAEAAACFYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAEQARAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAAC9hdmNDAfQADf/hABdn9AANkZsoIhHQgAAAAwCAAAAZB4oUywEABWjr48RIAAAAGHN0dHMAAAAAAAAAAQAAAMoAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAW4Y3R0cwAAAAAAAAC1AAAACAAABAAAAAABAAAGAAAAAAEAAAIAAAAAAwAABAAAAAABAAAIAAAAAAIAAAIAAAAAAgAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAADAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAgAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAQAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAAcc3RzYwAAAAAAAAABAAAAAQAAAMoAAAABAAADPHN0c3oAAAAAAAAAAAAAAMoAAAWyAAAAFwAAABsAAAAcAAAAHAAAABwAAAAcAAAAHQAAACEAAAAUAAAAHAAAAB0AAAAdAAAAHAAAABYAAAAUAAAAHgAAAB0AAAAkAAAAGQAAABQAAAAUAAAAHQAAABwAAAAhAAAAEwAAAB4AAAAcAAAAHwAAABUAAAATAAAAHgAAACEAAAAUAAAAIQAAABQAAAAdAAAAJQAAABQAAAAcAAAAHAAAABwAAAAkAAAAFAAAABsAAAAiAAAAIwAAABMAAAAUAAAAHgAAAB0AAAAjAAAAGgAAABQAAAAUAAAAHQAAABsAAAAcAAAAHAAAAB0AAAATAAAAEwAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAAB4AAAAoAAAAFHN0Y28AAAAAAAAAAQAAADAAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU3LjgzLjEwMA==\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "WK_ETIWpKMEQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "À présent, l'algorithme explore plus facilement et reste beaucoup moins bloqué dans des zones d'allers-retours entre 2 blocs. Toutefois, les résultats ne sont pas parfaits et il réussit rarement à récupérer toutes les récompenses positives."
      ]
    },
    {
      "metadata": {
        "id": "NHzSwVWqbjBY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "metadata": {
        "id": "z69lbKDzbjBY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "qWepCkabbjBZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***"
      ]
    }
  ]
}